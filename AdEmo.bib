% This file was created with JabRef 2.6.
% Encoding: Cp1252

@ARTICLE{Abbasi_15,
  author = {Abbasi, Ahmed and Lau, Raymond Y.K. and Brown, Donald E.},
  title = {Predicting Behavior},
  journal = {IEEE Intelligent Systems},
  year = {2015},
  owner = {Songfan},
  timestamp = {2015.05.26}
}

@ARTICLE{Le14,
  author = {Le An and Songfan Yang and Bir Bhanu},
  title = {Efficient Smile Detection by Extreme Learning Machine},
  journal = {Neurocomputing},
  year = {2014},
  owner = {Songfan},
  timestamp = {2014.05.23}
}

@ARTICLE{Best,
  author = {Roger J. Best},
  title = {GETTING STARTED USING MARKETING METRICS},
  journal = {White paper},
  owner = {Le},
  quality = {1},
  timestamp = {2013.05.29}
}

@MANUAL{SVMlib,
  title = {{LIBSVM}: A Library for Support Vector Machines},
  author = {Chih-Chung Chang and Chih-Jen Lin},
  year = {2001},
  note = {Software available at \url{http://www.csie.ntu.edu.tw/~cjlin/libsvm}}
}

@ARTICLE{LARS,
  author = {B. Efron and T. Hastie and I. Johnstone and R. Tibshirani},
  title = {Least angle regression},
  journal = {Annals of statistics},
  year = {2004},
  owner = {Songfan},
  timestamp = {2015.05.26}
}

@ARTICLE{Ekman93,
  author = {Paul Ekman},
  title = {Facial Expression and Emotion},
  journal = {American Psychologist},
  year = {1993},
  owner = {Le},
  quality = {1},
  timestamp = {2013.05.29}
}

@ARTICLE{Elpers03,
  author = {Josephine L.C.M. Woltman Elpers and Michel Wedel and Rik G.M. Pieters},
  title = {Why Do Consumers Stop Viewing Television Commercials? Two Experiments
	on the Influence of Moment-to-Moment Entertainment and Information
	Value},
  journal = {Journal of Marketing Research},
  year = {2003},
  owner = {Songfan},
  timestamp = {2014.04.14}
}

@ARTICLE{Gabarron13,
  author = {Elia Gabarron and Luis Fernandez-Luque and Manuel Armayones and Annie
	YS Lau},
  title = {Identifying Measures Used for Assessing Quality of YouTube Videos
	with Patient Health Information: A Review of Current Literature},
  journal = {Interactive Journal of Medical Research},
  year = {2013},
  number = {1},
  owner = {Le},
  quality = {1},
  timestamp = {2013.05.29}
}

@ARTICLE{CAS,
  author = {Wen Gao and Bo Cao and Shiguang Shan and Xilin Chen and Delong Zhou
	and Xiaohua Zhang and Debin Zhao},
  title = {The {CAS-PEAL} Large-Scale Chinese Face Database and Baseline Evaluations},
  journal = {IEEE Trans. on Systems, Man and Cybernetics, Part A},
  year = {2008}
}

@ARTICLE{MPIE,
  author = {Ralph Gross and Iain Matthews and Jeffrey Cohn and Takeo Kanade and
	Simon Baker},
  title = {Multi-{PIE}},
  journal = {Image and Vision Computing },
  year = {2010},
  issn = {0262-8856},
  keywords = {Face database}
}

@ARTICLE{Gustafson07,
  author = {Paul Gustafson and S. Siddarth},
  title = {Describing the Dynamics of Attention to TV Commercials: A Hierarchical
	{B}ayes Analysis of the Time to Zap an Ad},
  journal = {Journal of Applied Statistics},
  year = {2007},
  owner = {Le},
  quality = {1},
  timestamp = {2013.05.29}
}

@INPROCEEDINGS{Hu04,
  author = {Changbo Hu and Ya Chang and Feris, R. and Turk, M.},
  title = {Manifold Based Analysis of Facial Expression},
  booktitle = {IEEE Conf. on Computer Vision and Pattern Recognition Workshops},
  year = {2004},
  doi = {10.1109/CVPR.2004.116},
  keywords = {Active appearance model;Active shape model;Clustering algorithms;Computer
	vision;Deformable models;Face recognition;Facial features;Particle
	tracking;Pattern recognition;Video sequences}
}

@ARTICLE{Hyde04,
  author = {Paul Hyde and Edward Landry and Andrew Tipping},
  title = {Making The Perfect Marketer},
  journal = {Strategy + Business},
  year = {2004},
  owner = {Songfan},
  timestamp = {2013.10.03}
}

@INPROCEEDINGS{Kooij06,
  author = {Robert Kooij and Kamal Ahmed and Kjell Brunnstr\"{o}m},
  title = {Perceived Quality of Channel Zapping},
  booktitle = {Fifth IAESTED Int. Conf. on Communication Systems and Networks (CSN
	2006)},
  year = {2006}
}

@BOOK{kotler2009,
  title = {Marketing management},
  publisher = {Pearson Education India},
  year = {2009},
  author = {Kotler, Philip}
}

@ARTICLE{Kotsia07,
  author = {Kotsia, I. and Pitas, I.},
  title = {Facial Expression Recognition in Image Sequences Using Geometric
	Deformation Features and Support Vector Machines},
  journal = {IEEE Trans. on Image Processing},
  year = {2007},
  doi = {10.1109/TIP.2006.884954},
  issn = {1057-7149},
  keywords = {face recognition;image sequences;support vector machines;Candide grid
	nodes;SVM;facial action units;facial expression;facial expression
	recognition;geometric deformation features;grid-tracking;image sequences;support
	vector machines;video frames;Data mining;Face detection;Face recognition;Feature
	extraction;Image recognition;Image sequences;Pattern recognition;Support
	vector machine classification;Support vector machines;Virtual reality;Candide
	grid;Facial Action Coding S (FACS);Facial Action Unit (FAU);Support
	Vector Machines (SVMs);facial expression recognition;machine vision;pattern
	recognition;Algorithms;Artificial Intelligence;Face;Facial Expression;Humans;Image
	Enhancement;Image Interpretation, Computer-Assisted;Information Storage
	and Retrieval;Pattern Recognition, Automated;Subtraction Technique;Video
	Recording}
}

@INPROCEEDINGS{CKplus,
  author = {Lucey, P. and Cohn, J.F. and Kanade, T. and Saragih, J. and Ambadar,
	Z. and Matthews, I.},
  title = {The Extended Cohn-Kanade Dataset ({CK+}): A complete dataset for
	action unit and emotion-specified expression},
  booktitle = {IEEE Conf. on Computer Vision and Pattern Recognition Workshops},
  year = {2010},
  pages = {94-101},
  doi = {10.1109/CVPRW.2010.5543262},
  issn = {2160-7508},
  keywords = {emotion recognition;face recognition;image classification;support
	vector machines;CK database;SVM classifier;action unit;active appearance
	models;emotion detection;emotion-specified expression;extended Cohn-Kanade
	dataset;facial expression detection;leave-one-out subject cross-validation;linear
	support vector machine;Active appearance model;Code standards;Databases;Face
	detection;Gold;Measurement;Performance evaluation;Support vector
	machine classification;Support vector machines;Testing}
}

@INPROCEEDINGS{Lucey06,
  author = {Lucey, S. and Matthews, I. and Changbo Hu and Ambadar, Z. and De
	La Torre, F. and Cohn, J.},
  title = {{AAM} derived face representations for robust facial action recognition},
  booktitle = {Int. Conf. on Automatic Face and Gesture Recognition},
  year = {2006},
  doi = {10.1109/FGR.2006.17},
  keywords = {face recognition;image representation;active appearance model;face
	representations;normalization methods;robust facial action recognition;Active
	appearance model;Active shape model;Behavioral science;Databases;Face
	recognition;Gold;Motion measurement;Pattern recognition;Robots;Robustness}
}

@ARTICLE{spams,
  author = {J. Mairal and F. Bach and J. Ponce and G. Sapiro},
  title = {Online learning for matrix factorization and sparse coding},
  journal = {Journal of Machine Learning Research},
  year = {2010},
  owner = {Songfan},
  timestamp = {2015.05.27}
}

@ARTICLE{McDuff07,
  author = {McDuff, D. and Kaliouby, R.E. and Picard, R.W.},
  title = {Crowdsourcing Facial Responses to Online Videos},
  journal = {IEEE Trans. on Affective Computing},
  year = {2012},
  doi = {10.1109/T-AFFC.2012.19},
  issn = {1949-3045},
  keywords = {Internet;advertising;face recognition;statistics;video databases;video
	signal processing;Cohn-Kanade database;Internet;MMI database;commercial;facial
	behavior;facial region luminance;facial region movement;facial region
	pose;facial region position;facial region scale;facial response analysis;facial
	response collection;facial response crowdsourcing;head movement;media
	content;online video;smile response;statistics;trackable face video;Advertising;Content
	awareness;Ethics;Face recognition;Human factors;Internet;Media;Videos;Crowdsourcing;advertising;facial
	expressions;market research;nonverbal behavior}
}

@ARTICLE{McDuff_IVC14,
  author = {McDuff, D. and Kaliouby, R. and Senechal, T. and Demirdjian, D. and
	Picard, R},
  title = {Automatic Measurement of Ad Preferences from Facial Responses Gathered
	Over the Internet},
  journal = {Image and Vision Computing},
  year = {2014},
  owner = {Songfan},
  timestamp = {2014.04.14}
}

@INPROCEEDINGS{McDuff13,
  author = {Daniel McDuff and Rana El Kaliouby and Evan Kodra and Rosalind W.
	Picard},
  title = {Measuring Voter's Candidate Preference Based on Affective Responses
	to Election Debates},
  booktitle = {ACII},
  year = {2013},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  biburl = {http://dblp.uni-trier.de/rec/bib/conf/acii/McDuffKKP13}
}

@INPROCEEDINGS{amfed,
  author = {Daniel McDuff and Rana El Kaliouby and Thibaud Senechal and May Amr
	and Jeffrey F. Cohn and Rosalind W. Picard},
  title = {Affectiva-MIT Facial Expression Dataset (AM-FED): Naturalistic and
	Spontaneous Facial Expressions Collected In-the-Wild},
  booktitle = {CVPR Workshops},
  year = {2013},
  pages = {881-888}
}

@INPROCEEDINGS{Ojansivu_ICISP08,
  author = {Ojansivu, V. and Heikkil\"a, J.},
  title = {Blur Insensitive Texture Classification Using Local Phase Quantization},
  booktitle = {Int. Conf. on Image and Signal Processing},
  year = {2008},
  series = {ICISP '08},
  address = {Berlin, Heidelberg},
  publisher = {Springer-Verlag},
  acmid = {1426636},
  doi = {http://dx.doi.org/10.1007/978-3-540-69905-7_27},
  isbn = {978-3-540-69904-0},
  location = {Cherbourg-Octeville, France},
  numpages = {8}
}

@ARTICLE{Pashkevich12,
  author = {Max Pashkevich and Sundar Dorai-Raj and Melanie Kellar and Dan Zigmond},
  title = {Empowering Online Advertisements by Empowering Viewers with the Right
	to Choose},
  journal = {Journal of Advertising Research},
  year = {2012}
}

@TECHREPORT{Poels06,
  author = {Poels, K and Dewitte, Siegfried},
  title = {How to capture the heart? Reviewing 20 years of emotion measurement
	in advertising},
  institution = {Katholieke Universiteit Leuven},
  year = {2006},
  abstract = {In the latest decades, emotions have become an important research
	topic in all behavioral sciences, and not the least in advertising.
	Yet, advertising literature on how to measure emotions is not straightforward.
	The major aim of this article is to give an update on the different
	methods used for measuring emotions in advertising and to discuss
	their validity and applicability. We further draw conclusions on
	the relation between emotions and traditional measures of advertising
	effectiveness. We finally formulate recommendations on the use of
	the different methods and make suggestions for future research.},
  keywords = {Research; Emotions; Science; Advertising; Effectiveness; Recommendations}
}

@ARTICLE{Shan12,
  author = {Caifeng Shan},
  title = {Smile detection by boosting pixel differences},
  journal = {IEEE Trans. on Image Processing},
  year = {2012},
  doi = {10.1109/TIP.2011.2161587},
  issn = {1057-7149},
  keywords = {face recognition;image reconstruction;support vector machines;Gabor-feature-based
	support vector machine;boosting pixel differences;grayscale face
	images;smile detection;Accuracy;Face;Feature extraction;Lighting;Pixel;Support
	vector machines;AdaBoost;facial expression recognition;smile detection;Algorithms;Face;Facial
	Expression;Happiness;Humans;Image Enhancement;Image Interpretation,
	Computer-Assisted;Pattern Recognition, Automated;Reproducibility
	of Results;Sensitivity and Specificity;Signal Processing, Computer-Assisted;Subtraction
	Technique}
}

@ARTICLE{Siebert09,
  author = {Siebert, P. and Van Caenegem, T.N.M. and Wagner, M.},
  title = {Analysis and Improvements of Zapping Times in {IPTV} Systems},
  journal = {IEEE Trans. on Broadcasting},
  year = {2009},
  doi = {10.1109/TBC.2008.2012019},
  issn = {0018-9316},
  keywords = {IPTV;video coding;IPTV;channel change time;linear TV services;quality
	of experience;set-top box;video coding;zapping time;Cable TV;DSL;HDTV;IPTV;Internet;Multimedia
	systems;Satellite broadcasting;TV broadcasting;US Department of Transportation;Video
	coding;Channel change time;IGMP;MPEG-2/H.264 encoding;STB;SVC}
}

@ARTICLE{Teixeira12,
  author = {Thales Teixeira and Michel Wedel and Rik Pieters},
  title = {Emotion-Induced Engagement in Internet Video Advertisements},
  journal = {Journal of Marketing Research},
  year = {2012},
  owner = {Le},
  quality = {1},
  timestamp = {2013.05.29}
}

@ARTICLE{FEI,
  author = {Carlos Eduardo Thomaz and Gilson Antonio Giraldi},
  title = {A new ranking method for principal components analysis and its application
	to face image analysis },
  journal = {Image and Vision Computing },
  year = {2010},
  issn = {0262-8856},
  keywords = {Principal components analysis}
}

@INPROCEEDINGS{Valstar05,
  author = {Valstar, M.F. and Patras, I. and Pantic, M.},
  title = {Facial Action Unit Detection using Probabilistic Actively Learned
	Support Vector Machines on Tracked Facial Point Data},
  booktitle = {IEEE Conf. on Computer Vision and Pattern Recognition Workshops},
  year = {2005},
  doi = {10.1109/CVPR.2005.457},
  issn = {1063-6919},
  keywords = {Behavioral science;Biomedical imaging;Emotion recognition;Face detection;Face
	recognition;Image databases;Robustness;Signal analysis;Support vector
	machines;Testing}
}

@ARTICLE{Viola_IJCV04,
  author = {Paul Viola and Michael Jones},
  title = {Robust Real-time Face Detection},
  journal = {Int. Journal of Computer Vision},
  year = {2004}
}

@ARTICLE{Whitehill09,
  author = {Whitehill, J. and Littlewort, Gwen and Fasel, Ian and Bartlett, M.
	and Movellan, J.},
  title = {Toward Practical Smile Detection},
  journal = {IEEE Trans. on Pattern Analysis and Machine Intelligence},
  year = {2009},
  doi = {10.1109/TPAMI.2009.42},
  issn = {0162-8828},
  keywords = {face recognition;image registration;image representation;learning
	(artificial intelligence);object detection;visual databases;automatic
	facial expression recognition research;feature representation;human-level
	expression recognition accuracy;illumination conditions;image databases;image
	registration;machine learning approaches;practical smile detection;training
	data set;Face and gesture recognition;computer vision.;machine learning;Algorithms;Artificial
	Intelligence;Biometry;Computer Simulation;Face;Humans;Image Enhancement;Image
	Interpretation, Computer-Assisted;Models, Biological;Pattern Recognition,
	Automated;Reproducibility of Results;Sensitivity and Specificity;Smiling;Subtraction
	Technique}
}

@INPROCEEDINGS{Yang13,
  author = {Yang, S. and An, L. and Bhanu, B. and Thakoor, N.},
  title = {Improving Action Units Recognition Using Dense Flow-based Face Registration
	in Video},
  booktitle = {Int. Conf. on Automatic Face and Gesture Recognition},
  year = {2013}
}

@INPROCEEDINGS{Yang_FG15,
  author = {Songfan Yang and Le An and Mehran Kafai and Bir Bhanu},
  title = {To Skip or not to Skip? A Dataset of Spontaneous Affective Response
	of Online Advertising (SARA) for Audience Behavior Analysis},
  booktitle = {IEEE int. Conf. on Automatic Face Gesture Recognition},
  year = {2015},
  owner = {Songfan},
  timestamp = {2015.05.27}
}

@ARTICLE{Yang12,
  author = {Songfan Yang and Bhanu, B.},
  title = {Understanding Discrete Facial Expressions in Video Using an Emotion
	Avatar Image},
  journal = {IEEE Trans. on Systems, Man, and Cybernetics, Part B},
  year = {2012},
  doi = {10.1109/TSMCB.2012.2192269},
  issn = {1083-4419},
  keywords = {avatars;emotion recognition;face recognition;image classification;support
	vector machines;video signal processing;EAI representation;GEMEP-FERA;aggregate
	dynamic information;appearance-based information;associated reference
	image;avatar reference;discrete facial expression analysis;emotion
	avatar image;emotion inference;geometry-based information;image-based
	representation;linear support vector machine classifier;local binary
	patterns;local phase quantization;video frames;video-based facial
	expression recognition techniques;Avatars;Face;Face recognition;Feature
	extraction;Geometry;Image recognition;Avatar reference;Scale-invariant
	feature transform (SIFT) flow;emotion avatar image (EAI);face registration;person-independent
	emotion recognition}
}

@INPROCEEDINGS{Yang_FERA11,
  author = {Songfan Yang and Bir Bhanu},
  title = {Facial Expression Recognition Using Emotion Avatar Image},
  booktitle = {IEEE int. Conf. on Automatic Face Gesture Recognition Workshop on
	Facial Expression Recognition and Analysis Challenge},
  year = {2011},
  owner = {songfan},
  timestamp = {2011.05.23}
}

@ARTICLE{Yang_TAC14,
  author = {Songfan Yang and Mehran Kafai and Le An and Bir Bhanu},
  title = {Zapping Index:Using Smile to Measure Advertisement Zapping Likelihood},
  journal = {IEEE Trans. on Affective Computing},
  year = {2014},
  owner = {Songfan},
  timestamp = {2015.05.26}
}

@ARTICLE{Zhao07,
  author = {Guoying Zhao and Pietik\"ainen, M.},
  title = {Dynamic texture recognition Using Local Binary Patterns with an Application
	to Facial Expressions},
  journal = {IEEE Trans. on PAMI},
  year = {2007},
  doi = {10.1109/TPAMI.2007.1110},
  issn = {0162-8828},
  keywords = {dynamic texture recognition;facial expressions;facial image analysis;volume
	local binary patterns;face recognition;image texture;Algorithms;Artificial
	Intelligence;Biometry;Computer Security;Face;Facial Expression;Humans;Image
	Enhancement;Image Interpretation, Computer-Assisted;Pattern Recognition,
	Automated;Reproducibility of Results;Sensitivity and Specificity;Signal
	Processing, Computer-Assisted;Video Recording;}
}

@BOOK{pwc,
  title = {Global Entertainment and Media Outlook 2014-2018},
  publisher = {PricewaterhouseCoopers (PwC)},
  year = {2014},
  owner = {Songfan},
  timestamp = {2015.05.26}
}

